# app.py
import streamlit as st
import pandas as pd
import numpy as np
import joblib
from PIL import Image
import os

# --- Load d·ªØ li·ªáu & m√¥ h√¨nh ---
@st.cache_data
def load_data():
    df = joblib.load("rfm_data.pkl")
    if not df.index.dtype == "object":
        df.index = df.index.astype(str)
    return df

@st.cache_resource
def load_models():
    scaler = joblib.load("rfm_scaler.pkl")
    model = joblib.load("kmeans_model.pkl")
    return scaler, model

# --- H√†m √°nh x·∫° c·ª•m th√†nh nh√£n ---
def interpret_cluster(cluster_id):
    mapping = {
        0: "TRUNG B√åNH / KH√ÅCH PH·ªî TH√îNG",
        1: "CHURN / KH√ÅCH R·ªúI B·ªé",
        2: "VIP / KH√ÅCH GI√Å TR·ªä CAO"
    }
    return mapping.get(cluster_id, "Kh√¥ng x√°c ƒë·ªãnh")

# --- Giao di·ªán Streamlit ---
st.set_page_config(page_title="Ph√¢n c·ª•m kh√°ch h√†ng", layout="wide")
st.title("Trung T√¢m Tin H·ªçc")
st.subheader(":mortar_board: ƒê·ªì √°n t·ªët nghi·ªáp Data Science")
st.markdown("**Th·ª±c hi·ªán b·ªüi: Anh Th∆∞ - Giang S∆°n**")

# --- 1. Gi·ªõi thi·ªáu d·ª± √°n ---
st.header("1. Gi·ªõi thi·ªáu n·ªôi dung d·ª± √°n")
st.markdown("""
D·ª± √°n nh·∫±m ph√¢n kh√∫c kh√°ch h√†ng d·ª±a tr√™n m√¥ h√¨nh **RFM (Recency - Frequency - Monetary)**, gi√∫p doanh nghi·ªáp nh·∫≠n di·ªán ph√¢n c·ª•m c√°c kh√°ch h√†ng ƒë·ªÉ doanh nghi·ªáp c√≥ chi·∫øn l∆∞·ª£c ph√π h·ª£p:

**Quy tr√¨nh th·ª±c hi·ªán:**
- Ti·∫øn h√†nh EDA ƒë·ªÉ hi·ªÉu h√†nh vi kh√°ch h√†ng
- T√≠nh to√°n ch·ªâ s·ªë RFM
- Chu·∫©n h√≥a d·ªØ li·ªáu & √°p d·ª•ng KMeans clustering
- ƒê√°nh gi√° b·∫±ng GMM - PCA

**H√¨nh ·∫£nh minh h·ªça quy tr√¨nh:**
""")

image_files = [
    ("1.EDA_product.png", "EDA: Ph√¢n t√≠ch s·∫£n ph·∫©m"),
    ("2.EDA_sales.png", "EDA: Doanh thu theo ng√†y"),
    ("3.top_10.eda.png", "Top 10 kh√°ch h√†ng theo doanh thu"),
    ("4.RFM_historgram.png", "Bi·ªÉu ƒë·ªì histogram RFM"),
    ("5.ebow_kmeans.png", "L·ª±a ch·ªçn k (elbow method)"),
    ("6.bubble_chart_kmeans.png", "Ph√¢n c·ª•m KMeans qua bubble chart"),
    ("7.GMM-PCA.png", "Ph√¢n c·ª•m GMM-PCA")
]

for file, caption in image_files:
    if os.path.exists(file):
        st.image(file, caption=caption, use_container_width=True)
    else:
        st.warning(f" Kh√¥ng t√¨m th·∫•y file: `{file}`")

st.markdown("""
D·ª±a v√†o RFM (Recency - Frequency - Monetary), m·ªôt s·ªë thu·∫≠t to√°n s·ª≠ d·ª•ng nh·∫±m ph√¢n ra 3 t·ªáp kh√°ch h√†ng nh∆∞ sau:

- **Cluster 1: CHURN / KH√ÅCH R·ªúI B·ªé**: Recency cao, Frequency th·∫•p, Monetary th·∫•p ‚Üí kh√°ch ƒë√£ l√¢u kh√¥ng quay l·∫°i ‚Üí **C·∫ßn remarketing**
- **Cluster 2: VIP / GI√Å TR·ªä CAO**: Recency th·∫•p, Frequency cao, Monetary cao ‚Üí **Gi·ªØ ch√¢n b·∫±ng loyalty/∆∞u ƒë√£i ƒë·∫∑c bi·ªát**
- **Cluster 0: TRUNG B√åNH / PH·ªî TH√îNG**: Trung b√¨nh c·∫£ 3 ch·ªâ s·ªë ‚Üí **Kh√°ch ti·ªÅm nƒÉng ƒë·ªÉ upsell**
""")

# --- 2. Ph√¢n c·ª•m kh√°ch h√†ng theo RFM ---
st.header("2. Nh·∫≠p th√¥ng tin kh√°ch h√†ng")
df_rfm = load_data()
scaler, model = load_models()

input_method = st.radio("Ch·ªçn c√°ch nh·∫≠p th√¥ng tin kh√°ch h√†ng:", 
                        ["Nh·∫≠p m√£ kh√°ch h√†ng", "Nh·∫≠p th√¥ng tin kh√°ch h√†ng v√†o slider", "T·∫£i file .csv"])

# --- C√°ch 1: Nh·∫≠p m√£ kh√°ch h√†ng ---
if input_method == "Nh·∫≠p m√£ kh√°ch h√†ng":
    customer_id = st.text_input("Nh·∫≠p m√£ kh√°ch h√†ng", value="1808")
    st.write(f"M√£ kh√°ch h√†ng: **{customer_id}**")

    if customer_id in df_rfm.index:
        try:
            rfm_row = df_rfm.loc[[customer_id]][["Recency", "Frequency", "Monetary"]]
            scaled_input = scaler.transform(rfm_row)
            cluster_label = model.predict(scaled_input)[0]
            cluster_name = interpret_cluster(cluster_label)

            st.header("3. G·ª£i √Ω ph√¢n c·ª•m kh√°ch h√†ng")
            st.success(f":bar_chart: C·ª•m kh√°ch h√†ng s·ªë: **{cluster_label}** ‚Äì {cluster_name}")
        except Exception as e:
            st.error(f"Kh√¥ng th·ªÉ ph√¢n c·ª•m kh√°ch h√†ng n√†y: {str(e)}")
    else:
        st.error("M√£ kh√°ch h√†ng kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu.")

# --- C√°ch 2: Nh·∫≠p slider ---
elif input_method == "Nh·∫≠p th√¥ng tin kh√°ch h√†ng v√†o slider":
    st.subheader("Nh·∫≠p th√¥ng tin kh√°ch h√†ng")
    customer_data = []
    for i in range(5):
        st.write(f"Kh√°ch h√†ng {i+1}")
        r = st.slider(f"Recency (Kh√°ch {i+1})", 1, 365, 100, key=f"recency_{i}")
        f = st.slider(f"Frequency (Kh√°ch {i+1})", 1, 50, 5, key=f"frequency_{i}")
        m = st.slider(f"Monetary (Kh√°ch {i+1})", 1, 1000, 100, key=f"monetary_{i}")
        customer_data.append([r, f, m])

    df_customer = pd.DataFrame(customer_data, columns=["Recency", "Frequency", "Monetary"])

    st.header("3. Ph√¢n c·ª•m kh√°ch h√†ng")
    try:
        scaled_input = scaler.transform(df_customer)
        clusters = model.predict(scaled_input)
        df_customer["Cluster"] = clusters
        df_customer["Ph√¢n nh√≥m"] = df_customer["Cluster"].apply(interpret_cluster)

        st.dataframe(df_customer)
        for i, row in df_customer.iterrows():
            st.success(f" Kh√°ch h√†ng {i+1} thu·ªôc c·ª•m: **{row['Cluster']} ‚Äì {row['Ph√¢n nh√≥m']}**")

    except Exception as e:
        st.error(f"L·ªói khi ph√¢n c·ª•m: {str(e)}")

# --- C√°ch 3: T·∫£i file CSV ---
else:
    st.subheader("üìÇ Ho·∫∑c: T·∫£i file d·ªØ li·ªáu kh√°ch h√†ng l√™n (.csv)")
    st.markdown(" **Y√™u c·∫ßu:** File c·∫ßn c√≥ 3 c·ªôt: `Recency`, `Frequency`, `Monetary`. C·ªôt `CustomerID` l√† t√πy ch·ªçn.")
    uploaded_file = st.file_uploader("T·∫£i l√™n file CSV ch·ª©a th√¥ng tin RFM", type=["csv"])

    if uploaded_file is not None:
        try:
            df_uploaded = pd.read_csv(uploaded_file)
            required_cols = {"Recency", "Frequency", "Monetary"}

            if not required_cols.issubset(df_uploaded.columns):
                st.error(" File c·∫ßn c√≥ ƒë·∫ßy ƒë·ªß c√°c c·ªôt: Recency, Frequency, Monetary")
            else:
                df_input = df_uploaded[["Recency", "Frequency", "Monetary"]]
                scaled_input = scaler.transform(df_input)
                clusters = model.predict(scaled_input)
                df_uploaded["Cluster"] = clusters
                df_uploaded["Ph√¢n nh√≥m"] = df_uploaded["Cluster"].apply(interpret_cluster)

                st.success("‚úÖ Ph√¢n c·ª•m th√†nh c√¥ng!")
                st.dataframe(df_uploaded)

                for i, row in df_uploaded.iterrows():
                    st.info(f" Kh√°ch h√†ng {row.get('CustomerID', i+1)} thu·ªôc c·ª•m: **{row['Cluster']} ‚Äì {row['Ph√¢n nh√≥m']}**")

        except Exception as e:
            st.error(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω file: {str(e)}")
